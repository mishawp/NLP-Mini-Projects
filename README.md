# üß† NLP Mini Projects

–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç 10 —É—á–µ–±–Ω—ã—Ö –º–∏–Ω–∏-–ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (NLP), –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è –∫—É—Ä—Å–∞ [**Natural Language Processing Demystified**](https://www.nlpdemystified.org/). –ü—Ä–æ–µ–∫—Ç—ã –æ—Ö–≤–∞—Ç—ã–≤–∞—é—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ‚Äî –æ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ Transformer.

## ‚öôÔ∏è –°—Ç–µ–∫ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π

- `spaCy` (01, 02, 03, 06)
- `gensim` (03, 04, 05)
- `scikit-learn` (01)
- `torch` (02, 05, 06, 07, 08, 09, 10)
- `pytorch-lightning` (08, 09, 10)
- `tokenizers` (07, 08, 09)
- `transformers` (10)

## üí° –ß—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —ç—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

- –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã —Å –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏  
- –í–ª–∞–¥–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã–º–∏ –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ NLP: `Bag of Words`, `TF-IDF`, `Naive Bayes`, `LDA`, `Neural Networks`, `Embeddings`, `LSTM`, `Seq2Seq`, `Attention`, `Transformer`  
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–µ –Ω–æ—É—Ç–±—É–∫–∏

## üìö –ü—Ä–æ–µ–∫—Ç—ã

### [01. Classification ‚Äî Naive Bayes](01.Classification.Naive-Bayes.ipynb)

**–ó–∞–¥–∞—á–∞:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤  
**–î–∞—Ç–∞—Å–µ—Ç:** [20 Newsgroups](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `spaCy` (—É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–≤)  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** `TfidfVectorizer`, `CountVectorizer`  
**–ú–æ–¥–µ–ª—å:** `MultinomialNB` (–Ω–∞–∏–≤–Ω—ã–π –±–∞–π–µ—Å–æ–≤—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä)

---

### [02. Classification ‚Äî Neural Network](02.Classification.Neural-Network.ipynb)

**–ó–∞–¥–∞—á–∞:** –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤  
**–î–∞—Ç–∞—Å–µ—Ç:** [20 Newsgroups](https://scikit-learn.org/stable/datasets/real_world.html#the-20-newsgroups-text-dataset)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `spaCy`  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** `TfidfVectorizer`  
**–ú–æ–¥–µ–ª—å:** –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å

---

### [03. Topic Modeling ‚Äî LDA](03.Topic-Modeling.LDA.ipynb)

**–ó–∞–¥–∞—á–∞:** –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ  
**–î–∞—Ç–∞—Å–µ—Ç:** CNN Articles (‚âà90 000 –Ω–æ–≤–æ—Å—Ç–µ–π)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `spaCy`  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** `gensim.corpora.Dictionary` (`.doc2bow`)  
**–ú–æ–¥–µ–ª—å:** `LdaModel` (*Latent Dirichlet Allocation*)

---

### [04. Word Vectors ‚Äî gensim](04.Review.Word-Vectors-gensim.ipynb)

**–ó–∞–¥–∞—á–∞:** –†–∞–±–æ—Ç–∞ —Å –≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ —Å–ª–æ–≤ (*Word Embeddings*)  
**–ú–æ–¥–µ–ª—å:** –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–∞ –∫–æ—Ä–ø—É—Å–µ *Google News (2015)*  
**–¶–µ–ª—å:** –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏

---

### [05. Sentiment Analysis ‚Äî Neural Network](05.Sentiment-Analysis.Neural-Network.ipynb)

**–ó–∞–¥–∞—á–∞:** –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤  
**–î–∞—Ç–∞—Å–µ—Ç:** Yelp Polarity Reviews (Amazon)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** –ö–∞—Å—Ç–æ–º–Ω—ã–π `WordLevel`  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** Embedding —Å–ª–æ–π (—Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏)  
**–ú–æ–¥–µ–ª—å:** –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å

---

### [06. Part-of-Speech Tagging ‚Äî BiLSTM](06.Part-of-Speech-Tagging.Bidirectional-LSTM.ipynb)

**–ó–∞–¥–∞—á–∞:** –†–∞–∑–º–µ—Ç–∫–∞ —á–∞—Å—Ç–µ–π —Ä–µ—á–∏  
**–î–∞—Ç–∞—Å–µ—Ç:** –ö–æ—Ä–ø—É—Å—ã `nltk`: `treebank`, `brown`, `conll2000`  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** –ö–∞—Å—Ç–æ–º–Ω—ã–π `WordLevel`  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** Embedding —Å–ª–æ–π  
**–ú–æ–¥–µ–ª—å:** Bidirectional LSTM

---

### [07. Language Modeling ‚Äî LSTM](07.Language-Modelling.LSTM.ipynb)

**–ó–∞–¥–∞—á–∞:** –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —è–∑—ã–∫–∞  
**–î–∞—Ç–∞—Å–µ—Ç:** *The Art of War* (–°—É–Ω—å-—Ü–∑—ã)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `tokenizers.Tokenizer` (`WordLevel`)  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** One-Hot Encoding  
**–ú–æ–¥–µ–ª—å:** –î–≤—É—Ö—Å–ª–æ–π–Ω–∞—è LSTM

---

### [08. Machine Translation ‚Äî Seq2Seq + Attention](08.Machine-Translation.LSTM-Seq2Seq-Attention.ipynb)

**–ó–∞–¥–∞—á–∞:** –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (—Ä—É—Å—Å–∫–∏–π ‚Üí –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)  
**–î–∞—Ç–∞—Å–µ—Ç:** [Tatoeba](https://tatoeba.org/en/downloads)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `tokenizers.Tokenizer` (`WordLevel`)  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** Embedding —Å–ª–æ–π  
**–ú–æ–¥–µ–ª—å:** Seq2Seq LSTM —Å/–±–µ–∑ Attention

---

### [09. Machine Translation ‚Äî Transformer from Scratch](09.Machine-Translation.Transformer-from-Scratch.ipynb)

**–ó–∞–¥–∞—á–∞:** –ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ (—Ä—É—Å—Å–∫–∏–π ‚Üí –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)  
**–î–∞—Ç–∞—Å–µ—Ç:** [Tatoeba](https://tatoeba.org/en/downloads)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `tokenizers.Tokenizer` (`WordLevel` / `BPE`)  
**–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** Embedding —Å–ª–æ–π  
**–ú–æ–¥–µ–ª—å:** –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Transformer, —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å –Ω—É–ª—è

---

### [10. Question Answering ‚Äî distilRoBERTa](10.Question-Answering.Fine-Tuned-distilroberta.ipynb)

**–ó–∞–¥–∞—á–∞:** –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (Question Answering)  
**–î–∞—Ç–∞—Å–µ—Ç:** *SQuAD* (`Hugging Face datasets`)  
**–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:** `distilroberta-base` `AutoTokenizer`  
**–ú–æ–¥–µ–ª—å:** `distilroberta-base`
