{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa55f1f6",
   "metadata": {},
   "source": [
    "# Моделирование языка с использованием многослойного LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f159e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.normalizers import Lowercase\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "from tokenizers.decoders import Replace\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5806f1",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "Модель будет работать на уровне символов (в противоположность моделям на уровне слов). Это означает, что, получив на вход последовательность из одного или нескольких символов, модель должна будет предсказать следующий символ.\n",
    "\n",
    "Символьная языковая модель имеет следующие преимущества:\n",
    "- Меньше пространство предсказаний. В языке есть только ограниченный набор символов, в отличие от слов, которых тысяча.\n",
    "- Устойчивее к ситуациям, когда слово не встречалось в тренировочном наборе (out-of-vocabulary) и лучше понимает базовые механики языка (в том числе пунктуацию).\n",
    "\n",
    "С другой стороны, модели на уровне символов должны учиться распознавать целые последовательности букв, чтобы понимать отдельные слова (например, соединять «c», «a» и «t» в «cat»). Это делает обучение менее эффективным и может снижать качество работы модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3cfe3",
   "metadata": {},
   "source": [
    "## Сырой текст\n",
    "\n",
    "**Art of War by Sun Tzu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc24f92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already downloaded file art_of_war.txt\n"
     ]
    }
   ],
   "source": [
    "!gdown -c \"https://drive.google.com/uc?id=1IvmDXJQEAtTm1qZEC0ckcyq-SGXxfPDq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7157c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"art_of_war.txt\", \"r\") as f:\n",
    "    art_of_war = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afae3adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Sun Tzŭ said: The art of war is of vital importance to the State.\n",
      "\n",
      "2. It is a matter of life and death, a road either to safety or to\n",
      "ruin. Hence it is a subject of inquiry which can on no account be\n",
      "neglected.\n",
      "\n",
      "3. The art of war, then, is governed by five constant factors, to be\n",
      "taken into accou \n",
      "\n",
      "61054\n"
     ]
    }
   ],
   "source": [
    "print(art_of_war[:300], \"\\n\")\n",
    "print(len(art_of_war))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c77d67",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Простой посимвольный токенизатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3157f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.normalizer = Lowercase()\n",
    "tokenizer.pre_tokenizer = Split(r\"\", behavior=\"isolated\")\n",
    "tokenizer.decoder = Replace(\"\", \"\")\n",
    "\n",
    "tokenizer_trainer = WordLevelTrainer(special_tokens=[\"[UNK]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "664a361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator([art_of_war], tokenizer_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6fafc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря:  57\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер словаря: \", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081337af",
   "metadata": {},
   "source": [
    "Преобразуем весь текст в последовательность индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cba1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.encode(art_of_war)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "911269de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizers.Encoding"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8b9f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина векторизованного текста: 61054\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина векторизованного текста:\", len(seq.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14aeab56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '.', ' ', 's', 'u', 'n', ' ', 't', 'z', 'ŭ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b438973f",
   "metadata": {},
   "source": [
    "## Создание датасета\n",
    "\n",
    "Наши данные - это одна длинная последовательность. Его нужно разделить на обучающие образцы.\n",
    "\n",
    "На вход модель получает последовательность из `seq_len` символов из срезе `[idx:idx + seq_len]`. Таргетами будут символы из среза `[idx + 1 : idx + self.seq_len + 1]`.\n",
    "\n",
    "Например:\n",
    "- Вход: \"she swam in the lak_\";\n",
    "- Таргет/метка: \"_he swam in the lake\".\n",
    "\n",
    "Также будем использовать `one-hot` представления входных символов, так как словарь маленький и векторная близость не имеет смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bbbda9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesDataset(data.Dataset):\n",
    "    def __init__(self, seq: list[int], seq_len: int, vocab_size: int):\n",
    "        self.seq = torch.tensor(seq, dtype=torch.long)\n",
    "        self.seq_len = seq_len\n",
    "        # vocab_size include padding index\n",
    "        self.ohe = torch.eye(vocab_size, dtype=torch.float)\n",
    "        self.size = len(self.seq) - self.seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.seq[idx : idx + self.seq_len]\n",
    "        y = self.seq[idx + 1 : idx + self.seq_len + 1]\n",
    "        return self.ohe[x], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216c355",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec11dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            vocab_size, 128, num_layers=2, dropout=0.2, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y, (h_n, c_n) = self.lstm(x)\n",
    "        # y: (batch_size, seq_len, hidden_size)\n",
    "        out = self.out(y)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49fc208",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef494e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        criterion: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_dataloader: data.DataLoader,\n",
    "        val_dataloader: data.DataLoader,\n",
    "        epochs: int,\n",
    "        patience: int,\n",
    "        device: torch.device,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "\n",
    "    def compute_metrics(self, y_pred, y_true, loss):\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        perplexity = math.exp(loss) if loss < 20 else float(\"inf\")\n",
    "        return {\"accuracy\": accuracy, \"perplexity\": perplexity}\n",
    "\n",
    "    def _run_epoch(self, dataloader, train: bool = True):\n",
    "        if train:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        epoch_predicts = []\n",
    "        epoch_labels = []\n",
    "\n",
    "        ctx = torch.enable_grad() if train else torch.no_grad()\n",
    "        with ctx:\n",
    "            for X, y in tqdm(dataloader, desc=\"Train\" if train else \"Val\"):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "\n",
    "                outputs = self.model(X)  # (batch, seq_len, vocab_size)\n",
    "                loss = self.criterion(outputs.permute(0, 2, 1), y)\n",
    "\n",
    "                if train:\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                predicts = (\n",
    "                    outputs.detach().cpu().argmax(dim=-1).numpy().ravel()\n",
    "                )\n",
    "                labels = y.detach().cpu().numpy().ravel()\n",
    "                epoch_predicts.extend(predicts)\n",
    "                epoch_labels.extend(labels)\n",
    "\n",
    "        epoch_loss /= len(dataloader)\n",
    "        metrics = self.compute_metrics(\n",
    "            epoch_predicts, epoch_labels, epoch_loss\n",
    "        )\n",
    "        return epoch_loss, metrics\n",
    "\n",
    "    def _train_epoch(self):\n",
    "        return self._run_epoch(self.train_dataloader, train=True)\n",
    "\n",
    "    def _validate(self, dataloader=None):\n",
    "        if dataloader is None:\n",
    "            dataloader = self.val_dataloader\n",
    "        return self._run_epoch(dataloader, train=False)\n",
    "\n",
    "    def test(\n",
    "        self, test_dataloader: data.DataLoader\n",
    "    ) -> tuple[float, dict[str, float | int]]:\n",
    "        return self._validate(test_dataloader)\n",
    "\n",
    "    def __append_to_history(self, **kwargs):\n",
    "        for k in self.history:\n",
    "            self.history[k].append(kwargs[k])\n",
    "\n",
    "    def train(self):\n",
    "        self.history = dict(train_loss=[], train_accuracy=[])\n",
    "        best_score = float(\"inf\")\n",
    "        no_improve = 0\n",
    "        best_model = {\n",
    "            k: v.cpu().clone() for k, v in self.model.state_dict().items()\n",
    "        }\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_metrics = self._train_epoch()\n",
    "            self.__append_to_history(\n",
    "                train_loss=train_loss,\n",
    "                train_accuracy=train_metrics[\"accuracy\"],\n",
    "                train_perplexity=train_metrics[\"perplexity\"],\n",
    "            )\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
    "            print(\n",
    "                f\"Train Loss:       {train_loss:.3f}\\n\"\n",
    "                f\"Train Perplexity: {train_metrics['perplexity']:.3f}\\n\"\n",
    "                f\"Train Accuracy:   {train_metrics['accuracy']:.3f}\"\n",
    "            )\n",
    "            print()\n",
    "            if train_metrics[\"perplexity\"] < best_score:\n",
    "                best_score = train_metrics[\"perplexity\"]\n",
    "                best_model = {\n",
    "                    k: v.cpu().clone()\n",
    "                    for k, v in self.model.state_dict().items()\n",
    "                }\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "\n",
    "            if no_improve >= self.patience:\n",
    "                print(f\"Early stopping after {epoch + 1} epoch\")\n",
    "                self.model.load_state_dict(best_model)\n",
    "                break\n",
    "\n",
    "        print(f\"Best Perplexity: {best_score:.4f}\")\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd6c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel(tokenizer.get_vocab_size())\n",
    "\n",
    "batch_size = 16\n",
    "SEQ_LEN = 100\n",
    "train_dataset = SequencesDataset(\n",
    "    seq.ids, seq_len=SEQ_LEN, vocab_size=tokenizer.get_vocab_size()\n",
    ")\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 30\n",
    "patience = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "trainer = ModelTrainer(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    None,\n",
    "    epochs,\n",
    "    patience,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a98bbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 372.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss:       1.871\n",
      "Train Perplexity: 6.494\n",
      "Train Accuracy:   0.451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 348.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss:       1.119\n",
      "Train Perplexity: 3.060\n",
      "Train Accuracy:   0.658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 417.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss:       0.814\n",
      "Train Perplexity: 2.257\n",
      "Train Accuracy:   0.747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 394.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss:       0.666\n",
      "Train Perplexity: 1.947\n",
      "Train Accuracy:   0.792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 347.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss:       0.581\n",
      "Train Perplexity: 1.788\n",
      "Train Accuracy:   0.819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 417.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss:       0.526\n",
      "Train Perplexity: 1.692\n",
      "Train Accuracy:   0.837\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 397.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss:       0.487\n",
      "Train Perplexity: 1.627\n",
      "Train Accuracy:   0.849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 356.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss:       0.458\n",
      "Train Perplexity: 1.581\n",
      "Train Accuracy:   0.859\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 410.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss:       0.435\n",
      "Train Perplexity: 1.546\n",
      "Train Accuracy:   0.866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 388.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss:       0.417\n",
      "Train Perplexity: 1.517\n",
      "Train Accuracy:   0.872\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 352.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "Train Loss:       0.402\n",
      "Train Perplexity: 1.495\n",
      "Train Accuracy:   0.877\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 405.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "Train Loss:       0.389\n",
      "Train Perplexity: 1.476\n",
      "Train Accuracy:   0.881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 391.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "Train Loss:       0.378\n",
      "Train Perplexity: 1.460\n",
      "Train Accuracy:   0.885\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 358.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "Train Loss:       0.369\n",
      "Train Perplexity: 1.446\n",
      "Train Accuracy:   0.888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 386.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "Train Loss:       0.361\n",
      "Train Perplexity: 1.435\n",
      "Train Accuracy:   0.890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 386.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "Train Loss:       0.353\n",
      "Train Perplexity: 1.424\n",
      "Train Accuracy:   0.893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 399.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "Train Loss:       0.347\n",
      "Train Perplexity: 1.415\n",
      "Train Accuracy:   0.895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 422.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "Train Loss:       0.342\n",
      "Train Perplexity: 1.408\n",
      "Train Accuracy:   0.896\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 375.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "Train Loss:       0.336\n",
      "Train Perplexity: 1.399\n",
      "Train Accuracy:   0.898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 364.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "Train Loss:       0.331\n",
      "Train Perplexity: 1.392\n",
      "Train Accuracy:   0.900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 393.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "Train Loss:       0.327\n",
      "Train Perplexity: 1.387\n",
      "Train Accuracy:   0.901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 398.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "Train Loss:       0.323\n",
      "Train Perplexity: 1.381\n",
      "Train Accuracy:   0.902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:10<00:00, 361.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "Train Loss:       0.319\n",
      "Train Perplexity: 1.376\n",
      "Train Accuracy:   0.904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 395.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "Train Loss:       0.316\n",
      "Train Perplexity: 1.372\n",
      "Train Accuracy:   0.904\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 404.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "Train Loss:       0.313\n",
      "Train Perplexity: 1.367\n",
      "Train Accuracy:   0.906\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 397.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "Train Loss:       0.309\n",
      "Train Perplexity: 1.363\n",
      "Train Accuracy:   0.906\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 411.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "Train Loss:       0.307\n",
      "Train Perplexity: 1.359\n",
      "Train Accuracy:   0.907\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 395.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "Train Loss:       0.304\n",
      "Train Perplexity: 1.355\n",
      "Train Accuracy:   0.908\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 401.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "Train Loss:       0.301\n",
      "Train Perplexity: 1.352\n",
      "Train Accuracy:   0.909\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 3810/3810 [00:09<00:00, 404.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Train Loss:       0.299\n",
      "Train Perplexity: 1.349\n",
      "Train Accuracy:   0.910\n",
      "\n",
      "Best Perplexity: 1.3486\n"
     ]
    }
   ],
   "source": [
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820cd92",
   "metadata": {},
   "source": [
    "## Генерация текста\n",
    "\n",
    "Функция ниже будет принимать текст и генерировать несколько последующих символов.\n",
    "\n",
    "Будем использовать также параметр **температуры**. Следующий символ будет взять из вероятностного распределения. Температурой мы можем влиять на случайность.\n",
    "\n",
    "Если температура < 1 распределение вероятностей становиться \"более четким\" и модель будет более тщательно воспроизводить текст.\n",
    "\n",
    "Если повысить температуру, то распределение выравнивается, и повышается шанс того, что модель выберет что-то неожиданное.\n",
    "\n",
    "На практике достаточно высокая температура приводит к бессмыслице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38059cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(\n",
    "    model: nn.Module,\n",
    "    tokenizer: Tokenizer,\n",
    "    seed_text: str,\n",
    "    num_chars: int = 200,\n",
    "    temperature: float = 1.0,\n",
    "):\n",
    "    text = seed_text\n",
    "    vocab_size = tokenizer.get_vocab_size()\n",
    "\n",
    "    for _ in range(num_chars):\n",
    "        # Take the last *input_timesteps* number of characters in the text so far\n",
    "        # as input.\n",
    "        input_seq = tokenizer.encode(text[-SEQ_LEN:]).ids\n",
    "        ohe = torch.eye(vocab_size)\n",
    "        input_tensor = ohe[input_seq]\n",
    "\n",
    "        # Create probability distribution for next character adjusted by temperature.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # input: (seq_len, vocab_size) -> (1, seq_len, vocab_size)\n",
    "            # outputs: (1, seq_len, vocab_size)\n",
    "            # нам нужны вероятности только выхода последнего фрейма\n",
    "            outputs = model(input_tensor.unsqueeze(0).to(device)).cpu()\n",
    "            last_output = outputs[0, -1, :]  # (vocab_size,)\n",
    "\n",
    "        # Применяем softmax с температурой\n",
    "        logits = last_output / temperature\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Sample next character\n",
    "        next_char_idx = torch.multinomial(probas, num_samples=1).item()\n",
    "\n",
    "        # Convert index to character\n",
    "        next_char = tokenizer.id_to_token(next_char_idx)\n",
    "\n",
    "        # Add to running text\n",
    "        text += next_char\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "792b0ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana peels on the battlefield can snow attacked by heard of this way, we may\n",
      "succeed in accomplishing the essential part of our schemes if these five points.\n",
      "\n",
      "18. hence the saying: if you know the enemy and know yourself, your\n",
      "victory will not stand in doubt; if you know heaven and know earth, you\n",
      "may make your victory complete.\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    generate_text(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        \"Banana peels on the battlefield can\",\n",
    "        num_chars=300,\n",
    "        temperature=0.2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287be0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's time to release the Kraken when the wile consequences that must ensue.\n",
      "\n",
      "5. thus, though we have heard of stupid haste in war, cleverness has\n",
      "never been seen associated with long delays.\n",
      "\n",
      "6. there is no instance of a country having benefited from prolonged\n",
      "warfare.\n",
      "\n",
      "7. it is only one who is thoroughly acquainted with the evils of \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    generate_text(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        \"It's time to release the Kraken when\",\n",
    "        num_chars=300,\n",
    "        temperature=0.5,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bb96587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crush your enemies, see them driven before you, and you will be attacked by its head,\n",
      "and in making tactical dispositions, the highest pitch you can attain\n",
      "is to conceal them; conceal your dispositions, and you will be strongly fate in our hands.\n",
      "\n",
      "10. you may advantages to account unless\n",
      "we make use of locoly.\n",
      "\n",
      "28. nor rein to rese are officers and \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    generate_text(\n",
    "        model,\n",
    "        tokenizer,\n",
    "        \"Crush your enemies, see them driven before you, and\",\n",
    "        num_chars=300,\n",
    "        temperature=1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4122c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is best in life?\n",
      "on a pass, of compars, and cheakers offin wain, (1)\n",
      "desivalent proigs; and\n",
      "distantage, the army advantage.\n",
      "\n",
      "1. sun tzŭ said: there\n",
      "arm ig of infanctions of great, fore, we\n",
      "camail starth into areiving to time and general’s fall-your it; to be utpentains filia-tervance. sins if the tend-bawn\n",
      "and prik\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    generate_text(\n",
    "        model, tokenizer, \"What is best in life?\", num_chars=300, temperature=2\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
